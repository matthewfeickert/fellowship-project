{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Unbinned Likelihood Fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcf/anaconda3/envs/edwardenv/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow v1.3.0\n",
      "numpy v1.13.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import itertools # for fast looping\n",
    "import time # for timing loop\n",
    "# from iminuit import Minuit # http://iminuit.readthedocs.io/en/latest/installation.html\n",
    "import scipy.stats as stats\n",
    "import scipy.optimize as op\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Show the package versions used\n",
    "for package in [np, tf]:\n",
    "    print('{} v{}'.format(package.__name__, package.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup a Pandas dataframe for record keeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_df = pd.DataFrame(columns=('Fit Program', 'Number of Trials', 'Number of Events', 'Mean Time'),\n",
    "                      index=np.arange(0,4))\n",
    "fit_df_row = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will define the function that we are going to sample from and then fit to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is probably not even close to how I should do things\n",
    "import math\n",
    "def my_formula(formula_lambda, *args):\n",
    "    \"\"\"\n",
    "    Create and evaluate a function\n",
    "    \n",
    "    Args:\n",
    "        formula_lambda: `lambda`\n",
    "        *args: parameters to evaluate the formula with\n",
    "    \n",
    "    Returns:\n",
    "        The formula passed evaluated at the parameters passed\n",
    "    \n",
    "    Example:\n",
    "    >>> my_formula(lambda x, y: x * y, 1, 2)\n",
    "    2\n",
    "    >>> my_formula(lambda x, mu, sigma: \\\n",
    "                  math.exp(-1.0*(x - mu)*(x - mu)/math.sqrt(2*math.pi))/(sigma*math.sqrt(2*math.pi)),\n",
    "                  0, 0, 1)\n",
    "    0.3989422804014327\n",
    "    \"\"\"\n",
    "    return formula_lambda(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3989422804014327"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_formula(lambda x, mu, sigma: \\\n",
    "           math.exp(-1.0*(x - mu)*(x - mu)/math.sqrt(2*math.pi))/(sigma*math.sqrt(2*math.pi)),\n",
    "           0, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, let's just use TensorFlow's Normal distribution as it already exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kyle Lo has a very nice writeup on this: http://kyleclo.github.io/maximum-likelihood-in-tensorflow-pt-1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_and_scale(x):\n",
    "    \"\"\"\n",
    "    Center and scale input data\n",
    "    \n",
    "    Args:\n",
    "        x: `ndarray` of `floats` or `ints`, the data to be transformed.\n",
    "\n",
    "    Returns:\n",
    "        An `ndarray` of `floats` or `ints` that has mean and variance of 1\n",
    "    \"\"\"\n",
    "    center = x.min()\n",
    "    scale = x.max() - x.min()\n",
    "    return (x - center) / scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_true = 0.5\n",
    "sigma_true = 1.5\n",
    "\n",
    "n_events = 1000000\n",
    "n_trials = 10\n",
    "TYPE = np.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor for data\n",
    "X = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "mu_tf = tf.Variable(initial_value=np.random.normal(0., 0.1),\n",
    "                 dtype=tf.float32)\n",
    "# TensorFlow doesnâ€™t seem to provide a way to explicitly enforce variable constraints, so let sigma be phi^2\n",
    "phi_tf = tf.Variable(initial_value=np.random.normal(1., 0.1),\n",
    "                  dtype=tf.float32)\n",
    "sigma_tf = tf.square(phi_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "gaussian_dist = tf.distributions.Normal(loc=mu_tf, scale=sigma_tf)\n",
    "log_prob = gaussian_dist.log_prob(value=X)\n",
    "negative_log_likelihood = -1.0 * tf.reduce_sum(log_prob)\n",
    "\n",
    "# optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train_op = optimizer.minimize(loss=negative_log_likelihood)\n",
    "\n",
    "# gradient\n",
    "grad = tf.gradients(negative_log_likelihood, [mu_tf, phi_tf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show that the fit can work at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function convergence in 688 iterations!\n",
      "Fitted MLE: [0.5005, 0.1096]\n",
      "Target MLE: [0.5005, 0.1095]\n"
     ]
    }
   ],
   "source": [
    "# TOL_PARAM, TOL_LOSS, TOL_GRAD = 1e-8, 1e-8, 1e-8\n",
    "TOL_PARAM, TOL_LOSS, TOL_GRAD = 1e-6, 1e-6, 1e-6\n",
    "MAX_ITER = 10000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # initialize\n",
    "    sess.run(fetches=tf.global_variables_initializer())\n",
    "    \n",
    "    x_obs = center_and_scale(np.random.normal(loc=mu_true, scale=sigma_true, size=n_events))\n",
    "    \n",
    "    step = 1\n",
    "    obs_mu, obs_phi, obs_sigma = sess.run(fetches=[[mu_tf], [phi_tf], [sigma_tf]])\n",
    "    obs_loss = sess.run(fetches=[negative_log_likelihood], feed_dict={X: x_obs})\n",
    "    obs_grad = sess.run(fetches=[grad], feed_dict={X: x_obs})\n",
    "\n",
    "    while True:\n",
    "        # gradient step\n",
    "        sess.run(fetches=train_op, feed_dict={X: x_obs})\n",
    "\n",
    "        # update parameters\n",
    "        new_mu, new_phi, new_sigma = sess.run(fetches=[mu_tf, phi_tf, sigma_tf])\n",
    "        diff_norm = np.linalg.norm(np.subtract([new_mu, new_phi],\n",
    "                                               [obs_mu[-1], obs_phi[-1]]))\n",
    "\n",
    "        # update loss\n",
    "        new_loss = sess.run(fetches=negative_log_likelihood, feed_dict={X: x_obs})\n",
    "        loss_diff = np.abs(new_loss - obs_loss[-1])        \n",
    "\n",
    "        # update gradient\n",
    "        new_grad = sess.run(fetches=grad, feed_dict={X: x_obs})\n",
    "        grad_norm = np.linalg.norm(new_grad)\n",
    "\n",
    "        obs_mu.append(new_mu)\n",
    "        obs_phi.append(new_phi)\n",
    "        obs_sigma.append(new_sigma)\n",
    "        obs_loss.append(new_loss)\n",
    "        obs_grad.append(new_grad)\n",
    "\n",
    "        if diff_norm < TOL_PARAM:\n",
    "            print('Parameter convergence in {} iterations!'.format(step))\n",
    "            break\n",
    "\n",
    "        if loss_diff < TOL_LOSS:\n",
    "            print('Loss function convergence in {} iterations!'.format(step))\n",
    "            break\n",
    "\n",
    "        if grad_norm < TOL_GRAD:\n",
    "            print('Gradient convergence in {} iterations!'.format(step))\n",
    "            break\n",
    "\n",
    "        if step >= MAX_ITER:\n",
    "            print('Max number of iterations reached without convergence.')\n",
    "            break\n",
    "\n",
    "        step += 1\n",
    "\n",
    "# print results\n",
    "print('Fitted MLE: [{:.4f}, {:.4f}]'.format(obs_mu[-1], obs_sigma[-1]))\n",
    "print('Target MLE: [{:.4f}, {:.4f}]'.format(x_obs.mean(), x_obs.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time the fit (this should be done in a cleaner way ... this also takes a long time right now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function convergence in 708 iterations!\n",
      "Loss function convergence in 701 iterations!\n",
      "Loss function convergence in 709 iterations!\n",
      "Loss function convergence in 701 iterations!\n",
      "Loss function convergence in 707 iterations!\n",
      "Parameter convergence in 714 iterations!\n",
      "Loss function convergence in 710 iterations!\n",
      "Loss function convergence in 674 iterations!\n",
      "Loss function convergence in 666 iterations!\n",
      "Parameter convergence in 705 iterations!\n",
      "\n",
      "target mu = 0.5147, target sigma = 0.0982\n",
      "MLE mu = 0.5147, MLE sigma = 0.0982\n",
      "\n",
      "fit 1000000 points 10 times in 278.739785194397 seconds\n",
      "The average fit time is 27.873978519439696 seconds\n"
     ]
    }
   ],
   "source": [
    "TOL_PARAM, TOL_LOSS, TOL_GRAD = 1e-6, 1e-6, 1e-6\n",
    "MAX_ITER = 10000\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    for _ in itertools.repeat(None, n_trials):\n",
    "        # initialize\n",
    "        sess.run(fetches=tf.global_variables_initializer())\n",
    "        \n",
    "        x_obs = center_and_scale(np.random.normal(loc=mu_true, scale=sigma_true, size=n_events))\n",
    "\n",
    "        step = 1\n",
    "        obs_mu, obs_phi, obs_sigma = sess.run(fetches=[[mu_tf], [phi_tf], [sigma_tf]])\n",
    "        obs_loss = sess.run(fetches=[negative_log_likelihood], feed_dict={X: x_obs})\n",
    "        obs_grad = sess.run(fetches=[grad], feed_dict={X: x_obs})\n",
    "\n",
    "        while True:\n",
    "            # gradient step\n",
    "            sess.run(fetches=train_op, feed_dict={X: x_obs})\n",
    "\n",
    "            # update parameters\n",
    "            new_mu, new_phi, new_sigma = sess.run(fetches=[mu_tf, phi_tf, sigma_tf])\n",
    "            diff_norm = np.linalg.norm(np.subtract([new_mu, new_phi],\n",
    "                                                   [obs_mu[-1], obs_phi[-1]]))\n",
    "\n",
    "            # update loss\n",
    "            new_loss = sess.run(fetches=negative_log_likelihood, feed_dict={X: x_obs})\n",
    "            loss_diff = np.abs(new_loss - obs_loss[-1])        \n",
    "\n",
    "            # update gradient\n",
    "            new_grad = sess.run(fetches=grad, feed_dict={X: x_obs})\n",
    "            grad_norm = np.linalg.norm(new_grad)\n",
    "\n",
    "            obs_mu.append(new_mu)\n",
    "            obs_phi.append(new_phi)\n",
    "            obs_sigma.append(new_sigma)\n",
    "            obs_loss.append(new_loss)\n",
    "            obs_grad.append(new_grad)\n",
    "\n",
    "            if diff_norm < TOL_PARAM:\n",
    "                print('Parameter convergence in {} iterations!'.format(step))\n",
    "                break\n",
    "\n",
    "            if loss_diff < TOL_LOSS:\n",
    "                print('Loss function convergence in {} iterations!'.format(step))\n",
    "                break\n",
    "\n",
    "            if grad_norm < TOL_GRAD:\n",
    "                print('Gradient convergence in {} iterations!'.format(step))\n",
    "                break\n",
    "\n",
    "            if step >= MAX_ITER:\n",
    "                print('Max number of iterations reached without convergence.')\n",
    "                break\n",
    "\n",
    "            step += 1\n",
    "    \n",
    "end_time = time.time()\n",
    "time_duration = end_time - start_time\n",
    "mean_fit_time = time_duration/n_trials\n",
    "\n",
    "print(\"\\ntarget mu = {:.4f}, target sigma = {:.4f}\".format(x_obs.mean(), x_obs.std()))\n",
    "print(\"MLE mu = {:.4f}, MLE sigma = {:.4f}\".format(obs_mu[-1], obs_sigma[-1]))\n",
    "\n",
    "sess.close()\n",
    "\n",
    "print(\"\\nfit {} points {} times in {} seconds\".format(n_events, n_trials, time_duration))\n",
    "print(\"The average fit time is {} seconds\".format(mean_fit_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_df.loc[fit_df_row] = ['TensorFlow', n_trials, n_events, mean_fit_time]\n",
    "fit_df_row += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- This is old and bad and should be cleaned up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_model(model, n_samples, TYPE=np.float32):\n",
    "    \"\"\"\n",
    "    Sample the model n_samples times\n",
    "    \n",
    "    Args:\n",
    "        model: `tf.distributions` The model\n",
    "        n_samples: `int` The number of times the model is samples\n",
    "    \n",
    "    Returns:\n",
    "        The sampled points and their values: x,y\n",
    "        x: model.sample(n_samples)\n",
    "        y: model.prob(x)\n",
    "    \"\"\"\n",
    "    x = model.sample(n_samples)\n",
    "    y = model.prob(x)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        return sess.run(x), sess.run(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_log(X, mu, sigma, TYPE=np.float32):\n",
    "    \"\"\"The log of Normal(X | mu, sigma)\"\"\"\n",
    "    return -tf.log(tf.constant(np.sqrt(2 * np.pi), dtype=TYPE) * sigma) - \\\n",
    "        tf.pow(X - mu, 2) / (tf.constant(2, dtype=TYPE) * tf.pow(sigma, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(X, mu, sigma, TYPE=np.float32):\n",
    "    \"\"\"The NLL of Normal(X | mu, sigma)\"\"\"\n",
    "    return -tf.reduce_sum(normal_log(X, mu, sigma, TYPE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c.f. https://gist.github.com/ibab/45c3d886c182a1ea26d5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pdf of Gaussian of variable x with mean mu and standard deviation sigma\n",
    "# # mu = tf.Variable(0.)\n",
    "# mu = tf.Variable(np.float64(0.))\n",
    "# # sigma = tf.Variable(1.)\n",
    "# sigma = tf.Variable(np.float64(1.))\n",
    "# model_tf = tf.distributions.Normal(loc=mu, scale=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # My memory on my computer seems to fill up and stay full very fast by rerunning this\n",
    "# # so it seems that Python is not releasing anything\n",
    "\n",
    "# # MLE attempt\n",
    "# TYPE = np.float64 # This is required(?) for the fit to converge\n",
    "# # TYPE = np.float32\n",
    "\n",
    "# n_events = 1000000 # time of fit is very dependent on n_events\n",
    "# n_trials = 10\n",
    "\n",
    "# sess = tf.Session()\n",
    "\n",
    "# # def func(mu_, sigma_):\n",
    "# #     return sess.run(nll_, feed_dict={mu: mu_, sigma: sigma_})\n",
    "\n",
    "# def func(x):\n",
    "#     return sess.run(nll_, feed_dict={mu: x[0], sigma: x[1]})\n",
    "\n",
    "# mu_true = tf.Variable(np.float64(0.5))\n",
    "# sigma_true = tf.Variable(np.float64(1.5))\n",
    "# model_tf = tf.distributions.Normal(loc=mu_true, scale=sigma_true)\n",
    "\n",
    "# start_time = time.time()\n",
    "# for _ in itertools.repeat(None, n_trials):\n",
    "#     data = np.random.normal(0.5, 1.5, n_events)\n",
    "# #     data, _ = sample_model(model_tf, n_events) # this is wrong for some reason\n",
    "    \n",
    "#     # Define data as a variable so that it will be cached\n",
    "#     X = tf.Variable(data, name='data')\n",
    "    \n",
    "#     mu = tf.Variable(TYPE(1), name='mu')\n",
    "#     sigma = tf.Variable(TYPE(1), name='sigma')\n",
    "    \n",
    "#     init = tf.global_variables_initializer()\n",
    "#     sess.run(init)\n",
    "    \n",
    "#     nll_ = nll(X, mu, sigma, TYPE)\n",
    "    \n",
    "#     # To guard against excessive output\n",
    "#     if n_trials > 1:\n",
    "#         print_level = 0\n",
    "#     else:\n",
    "#         print_level = 1\n",
    "    \n",
    "#     ret = op.minimize(func, x0=[10, 10], bounds=[(-1, 100), (0.00001, 100)])\n",
    "# #     print(ret.x, ret.fun) # x is an array of fit values, fun is the value of the function passed\n",
    "    \n",
    "# end_time = time.time()\n",
    "# time_duration = end_time - start_time\n",
    "# mean_fit_time = time_duration/n_trials\n",
    "\n",
    "# print(\"true mu = {}, true sigma = {}\".format(sess.run(mu_true), sess.run(sigma_true)))\n",
    "# print(\"mu = {}, sigma = {}\".format(ret.x[0], ret.x[1]))\n",
    "      \n",
    "# sess.close()\n",
    "\n",
    "# print(\"\\nfit {} points {} times in {} seconds\".format(n_events, n_trials, time_duration))\n",
    "# print(\"The average fit time is {} seconds\".format(mean_fit_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.linspace(-5.0, 5.0, num=10000)\n",
    "# plt.figure(1)\n",
    "\n",
    "# sample_distribution = stats.norm.pdf(x, ret.x[0], ret.x[1])\n",
    "\n",
    "# # Plot histogram of samples\n",
    "# hist_count, bins, _ = plt.hist(data, 50, normed=True) #Norm to keep distribution in view\n",
    "# plt.plot(x, sample_distribution, linewidth=2, color='black')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example\n",
    "# test_x, test_y = sample_model(model_tf, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_x)\n",
    "# print(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit in SciPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit using `rv_continuous.fit()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPE = np.float64\n",
    "\n",
    "# Using the continuous random variable class\n",
    "# https://docs.scipy.org/doc/scipy-0.19.0/reference/generated/scipy.stats.rv_continuous.html\n",
    "from scipy.stats import rv_continuous\n",
    "class model_gen(rv_continuous):\n",
    "    \"\"\"Normal distribution\"\"\"\n",
    "    def _pdf(self, x):\n",
    "        return np.exp(-x**2 / 2.) / np.sqrt(2.0 * np.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show that the fit can work at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLE mean: 0.5016512908960371\n",
      "MLE standard deviation: 1.500075735274\n"
     ]
    }
   ],
   "source": [
    "scipy_gaussian = model_gen(name='gaussian')\n",
    "\n",
    "mu_true = 0.5\n",
    "sigma_true = 1.5\n",
    "\n",
    "X = np.random.normal(mu_true, sigma_true, n_events).astype(TYPE)\n",
    "\n",
    "# Return MLEs for shape, location, and scale parameters from data\n",
    "# https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.rv_continuous.fit.html\n",
    "scipy_ret = scipy_gaussian.fit(X)\n",
    "\n",
    "print('MLE mean: {}'.format(scipy_ret[0]))\n",
    "print('MLE standard deviation: {}'.format(scipy_ret[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time the fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true mu = 0.5, true sigma = 1.5\n",
      "MLE mu = 0.5006687689956756, MLE sigma = 1.4992090511031169\n",
      "\n",
      "fit 1000000 points 10 times in 207.31614136695862 seconds\n",
      "The average fit time is 20.73161413669586 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for _ in itertools.repeat(None, n_trials):\n",
    "    X = np.random.normal(mu_true, sigma_true, n_events).astype(TYPE)\n",
    "    scipy_ret = scipy_gaussian.fit(X)\n",
    "    \n",
    "end_time = time.time()\n",
    "time_duration = end_time - start_time\n",
    "mean_fit_time = time_duration/n_trials\n",
    "\n",
    "print(\"true mu = {}, true sigma = {}\".format(mu_true, sigma_true))\n",
    "print(\"MLE mu = {}, MLE sigma = {}\".format(scipy_ret[0], scipy_ret[1]))\n",
    "\n",
    "print(\"\\nfit {} points {} times in {} seconds\".format(n_events, n_trials, time_duration))\n",
    "print(\"The average fit time is {} seconds\".format(mean_fit_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_df.loc[fit_df_row] = ['SciPy: rv_continuous', n_trials, n_events, mean_fit_time]\n",
    "fit_df_row += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit using `optimize.minimize()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the NLL for our Gaussian model --- the function we want to minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(params, data):\n",
    "    \"\"\"\n",
    "    The negative log likelihood of Normal(X | loc, scale).\n",
    "    Designed to be a callable for scipy.optimize.minimize()\n",
    "    \n",
    "    Args:\n",
    "        params: `tuple` or `array` of `floats` or `ints`, the parameters of the model.\n",
    "        data: `ndarray` of `floats` or `ints`, the sampeled data.\n",
    "\n",
    "    Returns:\n",
    "        `float`, the negative log likelihood of Normal(data | loc, params).\n",
    "        \n",
    "    Example:\n",
    "    >>> loc, scale, n_events = 0, 1, 1000\n",
    "    >>> X = np.random.normal(loc, scale, n_events)\n",
    "    >>> nll([loc, scale], X)\n",
    "    502.01978041191808\n",
    "    \"\"\"\n",
    "    loc, scale = params\n",
    "    return len(data) * np.log(scale) + np.sum((data - loc) ** 2) / (2 * scale ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show that the fit can work at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLE mean: 0.5012828283110892\n",
      "MLE standard deviation: 1.496983954490524\n"
     ]
    }
   ],
   "source": [
    "mu_true = 0.5\n",
    "sigma_true = 1.5\n",
    "\n",
    "X = np.random.normal(mu_true, sigma_true, n_events).astype(TYPE)\n",
    "\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize\n",
    "op_ret = op.minimize(nll, x0=[10,10], args=(X), bounds=((None, None), (0.00001, None)))\n",
    "\n",
    "print('MLE mean: {}'.format(op_ret.x[0]))\n",
    "print('MLE standard deviation: {}'.format(op_ret.x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time the fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true mu = 0.5, true sigma = 1.5\n",
      "MLE mu = 0.49725592819625203, MLE sigma = 1.500443546344019\n",
      "\n",
      "fit 1000000 points 10 times in 5.191132545471191 seconds\n",
      "The average fit time is 0.5191132545471191 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for _ in itertools.repeat(None, n_trials):\n",
    "    X = np.random.normal(mu_true, sigma_true, n_events).astype(TYPE)\n",
    "    op_ret = op.minimize(nll, x0=[10,10], args=(X), bounds=((None, None), (0.00001, None)))\n",
    "    \n",
    "end_time = time.time()\n",
    "time_duration = end_time - start_time\n",
    "mean_fit_time = time_duration/n_trials\n",
    "\n",
    "print(\"true mu = {}, true sigma = {}\".format(mu_true, sigma_true))\n",
    "print(\"MLE mu = {}, MLE sigma = {}\".format(op_ret.x[0], op_ret.x[1]))\n",
    "\n",
    "print(\"\\nfit {} points {} times in {} seconds\".format(n_events, n_trials, time_duration))\n",
    "print(\"The average fit time is {} seconds\".format(mean_fit_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_df.loc[fit_df_row] = ['SciPy: optimize', n_trials, n_events, mean_fit_time]\n",
    "fit_df_row += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit in RooFit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_df.loc[fit_df_row] = ['RooFit', n_trials, n_events, mean_fit_time]\n",
    "fit_df_row += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fit Program</th>\n",
       "      <th>Number of Trials</th>\n",
       "      <th>Number of Events</th>\n",
       "      <th>Mean Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>10</td>\n",
       "      <td>1000000</td>\n",
       "      <td>27.874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SciPy: rv_continuous</td>\n",
       "      <td>10</td>\n",
       "      <td>1000000</td>\n",
       "      <td>20.7316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SciPy: optimize</td>\n",
       "      <td>10</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0.519113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RooFit</td>\n",
       "      <td>10</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0.519113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Fit Program Number of Trials Number of Events Mean Time\n",
       "0            TensorFlow               10          1000000    27.874\n",
       "1  SciPy: rv_continuous               10          1000000   20.7316\n",
       "2       SciPy: optimize               10          1000000  0.519113\n",
       "3                RooFit               10          1000000  0.519113"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
